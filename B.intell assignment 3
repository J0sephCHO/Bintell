


In [255]:



# Mounting Google Drive
from google.colab import drive
drive.mount('/content/drive')






Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).





In [256]:



# Import libraries
import pandas as pd
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.svm import SVR
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn import preprocessing
from sklearn import linear_model
from sklearn.tree import DecisionTreeRegressor
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt





In [257]:



# Read data
wine_quality = pd.read_csv("/content/drive/MyDrive/IS470_data/winequality-red.csv")
wine_quality





Out[257]:




fixed acidity
volatile acidity
citric acid
residual sugar
chlorides
free sulfur dioxide
total sulfur dioxide
density
pH
sulphates
alcohol
quality
 
0
7.4
0.700
0.00
1.9
0.076
11.0
34.0
0.99780
3.51
0.56
9.4
5
1
7.8
0.880
0.00
2.6
0.098
25.0
67.0
0.99680
3.20
0.68
9.8
5
2
7.8
0.760
0.04
2.3
0.092
15.0
54.0
0.99700
3.26
0.65
9.8
5
3
11.2
0.280
0.56
1.9
0.075
17.0
60.0
0.99800
3.16
0.58
9.8
6
4
7.4
0.700
0.00
1.9
0.076
11.0
34.0
0.99780
3.51
0.56
9.4
5
...
...
...
...
...
...
...
...
...
...
...
...
...
1594
6.2
0.600
0.08
2.0
0.090
32.0
44.0
0.99490
3.45
0.58
10.5
5
1595
5.9
0.550
0.10
2.2
0.062
39.0
51.0
0.99512
3.52
0.76
11.2
6
1596
6.3
0.510
0.13
2.3
0.076
29.0
40.0
0.99574
3.42
0.75
11.0
6
1597
5.9
0.645
0.12
2.0
0.075
32.0
44.0
0.99547
3.57
0.71
10.2
5
1598
6.0
0.310
0.47
3.6
0.067
18.0
42.0
0.99549
3.39
0.66
11.0
6

1599 rows × 12 columns




Following my perusal of the data from Google Drive, I must assess the data's quality. In the meanwhile, it's critical to deal with missing data and determine whether any variables are associated.



In [258]:



# Show the head rows of a data frame
wine_quality.head()





Out[258]:




fixed acidity
volatile acidity
citric acid
residual sugar
chlorides
free sulfur dioxide
total sulfur dioxide
density
pH
sulphates
alcohol
quality
 
0
7.4
0.70
0.00
1.9
0.076
11.0
34.0
0.9978
3.51
0.56
9.4
5
1
7.8
0.88
0.00
2.6
0.098
25.0
67.0
0.9968
3.20
0.68
9.8
5
2
7.8
0.76
0.04
2.3
0.092
15.0
54.0
0.9970
3.26
0.65
9.8
5
3
11.2
0.28
0.56
1.9
0.075
17.0
60.0
0.9980
3.16
0.58
9.8
6
4
7.4
0.70
0.00
1.9
0.076
11.0
34.0
0.9978
3.51
0.56
9.4
5





I must ascertain the data type for each variable in order to establish whether or not dummy coding is required.



In [259]:



# Examine variable type
wine_quality.dtypes





Out[259]:

fixed acidity           float64
volatile acidity        float64
citric acid             float64
residual sugar          float64
chlorides               float64
free sulfur dioxide     float64
total sulfur dioxide    float64
density                 float64
pH                      float64
sulphates               float64
alcohol                 float64
quality                   int64
dtype: object



In [260]:



wine_quality.keys()





Out[260]:

Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',
       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',
       'pH', 'sulphates', 'alcohol', 'quality'],
      dtype='object')



In [261]:



wine_quality.isnull().sum()





Out[261]:

fixed acidity           0
volatile acidity        0
citric acid             0
residual sugar          0
chlorides               0
free sulfur dioxide     0
total sulfur dioxide    0
density                 0
pH                      0
sulphates               0
alcohol                 0
quality                 0
dtype: int64



In [262]:



snsplot = sns.histplot(x='pH', data = wine_quality)
snsplot.set_title("Histogram of wine quality in the wine data set")





Out[262]:

Text(0.5, 1.0, 'Histogram of wine quality in the wine data set')



In [263]:



# exploring relationships among all numeric variables: correlation matrix
wine_quality.corr()





Out[263]:




fixed acidity
volatile acidity
citric acid
residual sugar
chlorides
free sulfur dioxide
total sulfur dioxide
density
pH
sulphates
alcohol
quality
 
fixed acidity
1.000000
-0.256131
0.671703
0.114777
0.093705
-0.153794
-0.113181
0.668047
-0.682978
0.183006
-0.061668
0.124052
volatile acidity
-0.256131
1.000000
-0.552496
0.001918
0.061298
-0.010504
0.076470
0.022026
0.234937
-0.260987
-0.202288
-0.390558
citric acid
0.671703
-0.552496
1.000000
0.143577
0.203823
-0.060978
0.035533
0.364947
-0.541904
0.312770
0.109903
0.226373
residual sugar
0.114777
0.001918
0.143577
1.000000
0.055610
0.187049
0.203028
0.355283
-0.085652
0.005527
0.042075
0.013732
chlorides
0.093705
0.061298
0.203823
0.055610
1.000000
0.005562
0.047400
0.200632
-0.265026
0.371260
-0.221141
-0.128907
free sulfur dioxide
-0.153794
-0.010504
-0.060978
0.187049
0.005562
1.000000
0.667666
-0.021946
0.070377
0.051658
-0.069408
-0.050656
total sulfur dioxide
-0.113181
0.076470
0.035533
0.203028
0.047400
0.667666
1.000000
0.071269
-0.066495
0.042947
-0.205654
-0.185100
density
0.668047
0.022026
0.364947
0.355283
0.200632
-0.021946
0.071269
1.000000
-0.341699
0.148506
-0.496180
-0.174919
pH
-0.682978
0.234937
-0.541904
-0.085652
-0.265026
0.070377
-0.066495
-0.341699
1.000000
-0.196648
0.205633
-0.057731
sulphates
0.183006
-0.260987
0.312770
0.005527
0.371260
0.051658
0.042947
0.148506
-0.196648
1.000000
0.093595
0.251397
alcohol
-0.061668
-0.202288
0.109903
0.042075
-0.221141
-0.069408
-0.205654
-0.496180
0.205633
0.093595
1.000000
0.476166
quality
0.124052
-0.390558
0.226373
0.013732
-0.128907
-0.050656
-0.185100
-0.174919
-0.057731
0.251397
0.476166
1.000000





Partitioning the data¶



In [264]:



# Partition the data
target = wine_quality['quality']
predictors = wine_quality.drop(['quality'],axis=1)
predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size=0.3, random_state=0)
print(predictors_train.shape, predictors_test.shape, target_train.shape, target_test.shape)






(1119, 11) (480, 11) (1119,) (480,)






I must examine the distribution of the target variable—quality—in the testing data set after partitioning the data.



In [265]:



snsplot = sns.histplot(data = target_train)
snsplot.set_title("Histogram of quality in the training data set")





Out[265]:

Text(0.5, 1.0, 'Histogram of quality in the training data set')



In [266]:



snsplot = sns.histplot(data = target_test)
snsplot.set_title("Histogram of quality in the testing data set")





Out[266]:

Text(0.5, 1.0, 'Histogram of quality in the testing data set')




Linear Regression¶




To comprehend and quantify the link between two numerical variables, use simple linear regression.
Making a basic linear regression model and fitting it to a dataset is the first stage in developing a simple linear regression model. I created a straightforward linear regression model using just "alcohol" as the predictor in this dataset.



In [267]:



model1 = linear_model.LinearRegression()
model1.fit(predictors_train[['alcohol']], target_train)





Out[267]:



LinearRegression()
In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.

On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.


LinearRegression

LinearRegression()




I have to show the model summary once my model has been fitted to the dataset.



In [268]:



X2 = sm.add_constant(predictors_train[['alcohol']])
y = target_train
est = sm.OLS(y, X2)
est2 = est.fit()
print(est2.summary())






                            OLS Regression Results                            
==============================================================================
Dep. Variable:                quality   R-squared:                       0.214
Model:                            OLS   Adj. R-squared:                  0.213
Method:                 Least Squares   F-statistic:                     303.8
Date:                Wed, 08 Nov 2023   Prob (F-statistic):           2.29e-60
Time:                        02:07:16   Log-Likelihood:                -1235.3
No. Observations:                1119   AIC:                             2475.
Df Residuals:                    1117   BIC:                             2485.
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
const          1.9289      0.215      8.985      0.000       1.508       2.350
alcohol        0.3576      0.021     17.430      0.000       0.317       0.398
==============================================================================
Omnibus:                       24.052   Durbin-Watson:                   2.102
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               39.006
Skew:                          -0.173   Prob(JB):                     3.39e-09
Kurtosis:                       3.847   Cond. No.                         104.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.






The regression model's quality of fit is gauged by the R-square. With a value of 0.214, the variable "alcohol" accounts for approximately 21.4% of the variability in the "quality". Stated differently, the majority of the observed fluctuations in the dependent variable (quality) cannot be explained by "alcohol."
Alcohol and intercepts are statistically significant predictors of the dependent variable (quality), since both P-values are 0.
The coefficient of alcohol in this model is 0.3576, meaning that a unit change in alcohol would result in an approximate 0.3756 rise in quality. The coefficient of alcohol indicates the change in the dependent variable, or quality.



In [269]:



prediction_on_test = model1.predict(predictors_test[['alcohol']])






Following my predictions, I calculated the mean absolute error (MAE) and root mean square error (RMSE) to assess the overall performance.



In [270]:



MAE = mean_absolute_error(target_test, prediction_on_test)
RMSE = mean_squared_error(target_test, prediction_on_test, squared=False)
print("MAE:", MAE)
print("RMSE:", RMSE)






MAE: 0.5230974814995663
RMSE: 0.6623121357628291





In [271]:



sns.lmplot(x='alcohol', y='quality', data= wine_quality)
plt.xlabel('alcohol')
plt.ylabel('quality')
plt.title('Scatterplot of alcohol vs. quality')
plt.show()





In [272]:



plt.figure(figsize=(8, 6))
sns.scatterplot(x=target_test, y=prediction_on_test)
plt.plot([min(target_test), max(target_test)], [min(target_test), max(target_test)], linestyle='--', color='gray')
plt.title("Actual vs. Predicted (Linear Regression - Alcohol)")
plt.xlabel("Actual Quality Values")
plt.ylabel("Predicted Quality Values")





Out[272]:

Text(0, 0.5, 'Predicted Quality Values')




Multiple Linear Regression¶




In order to take into consideration many variables, multiple linear regression expands upon the ideas of basic linear regression.
Making a multiple linear regression model and fitting it to a dataset is the first stage in developing a multiple linear regression model.



In [273]:



model2 = linear_model.LinearRegression()
model2.fit(predictors_train, target_train)





Out[273]:



LinearRegression()
In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.

On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.


LinearRegression

LinearRegression()




summary of multiple linear regression model



In [274]:



import statsmodels.api as sm
X2 = sm.add_constant(predictors_train)
y = target_train
est = sm.OLS(y, X2)
est2 = est.fit()
print(est2.summary())






                            OLS Regression Results                            
==============================================================================
Dep. Variable:                quality   R-squared:                       0.371
Model:                            OLS   Adj. R-squared:                  0.365
Method:                 Least Squares   F-statistic:                     59.35
Date:                Wed, 08 Nov 2023   Prob (F-statistic):          1.86e-103
Time:                        02:07:17   Log-Likelihood:                -1110.6
No. Observations:                1119   AIC:                             2245.
Df Residuals:                    1107   BIC:                             2305.
Df Model:                          11                                         
Covariance Type:            nonrobust                                         
========================================================================================
                           coef    std err          t      P>|t|      [0.025      0.975]
----------------------------------------------------------------------------------------
const                   21.0111     25.418      0.827      0.409     -28.861      70.883
fixed acidity            0.0202      0.031      0.651      0.515      -0.041       0.081
volatile acidity        -1.2139      0.142     -8.537      0.000      -1.493      -0.935
citric acid             -0.0985      0.180     -0.548      0.584      -0.451       0.254
residual sugar           0.0221      0.018      1.259      0.208      -0.012       0.057
chlorides               -1.8976      0.484     -3.925      0.000      -2.846      -0.949
free sulfur dioxide      0.0020      0.003      0.774      0.439      -0.003       0.007
total sulfur dioxide    -0.0030      0.001     -3.534      0.000      -0.005      -0.001
density                -16.7249     25.954     -0.644      0.519     -67.649      34.199
pH                      -0.3977      0.230     -1.733      0.083      -0.848       0.053
sulphates                0.8542      0.132      6.459      0.000       0.595       1.114
alcohol                  0.2675      0.031      8.533      0.000       0.206       0.329
==============================================================================
Omnibus:                       17.572   Durbin-Watson:                   2.098
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               22.901
Skew:                          -0.192   Prob(JB):                     1.06e-05
Kurtosis:                       3.586   Cond. No.                     1.15e+05
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.15e+05. This might indicate that there are
strong multicollinearity or other numerical problems.






The summary indicates that because the R-squared is 0.371, 37.1 of the variability in the dependent variable (quality) is explained. The statistical significance of a variable as a predictor is determined by its p-value. The quality can be statistically predicted by volatile acidity, alcohol, sulphates, chlorides, and total sulfur dioxide.The top three crucial factors are:
Volatile Acidity (Coefficient: -1.2139): A drop in the target variable is anticipated as volatile acidity rises.(Keeping all factors equal, a one unit increase in volatile acidity causes a quality loss of about 1.2139 units.)
Alcohol (Coefficient: 0.2675): The target variable is projected to rise as the wine's alcohol level rises (keeping other variables fixed, a one-unit increase in alcohol corresponds to an increase of around 0.2675 units in quality).
Sulphates (Coefficient: 0.8542): An increase in the target variable is anticipated in proportion to the wine's sulfate content.(Keeping all factors equal, a rise of one unit in sulphates corresponds to an increase of around 0.8542 units in quality.) As a result, decreasing the volatile acidity of wine is the better course of action.



In [275]:



prediction_on_test = model2.predict(predictors_test)






Examine the evaluation results on testing data: MAE and RMSE



In [276]:



MAE = mean_absolute_error(target_test, prediction_on_test)
RMSE = mean_squared_error(target_test, prediction_on_test, squared=False)
print("MAE:", MAE)
print("RMSE:", RMSE)






MAE: 0.4871262164592797
RMSE: 0.6330721652189466





In [277]:



sns.lmplot(x='volatile acidity', y='quality', data= wine_quality)
plt.xlabel('volatile acidity')
plt.ylabel('quality')
plt.title('Scatterplot of volatile acidity vs. quality')
plt.show()





In [278]:



plt.figure(figsize=(8, 6))
sns.scatterplot(x=target_test, y=prediction_on_test)
plt.plot([min(target_test), max(target_test)], [min(target_test), max(target_test)], linestyle='--', color='yellow')
plt.title("Actual vs. Predicted (Mutiple Linear Regression )")
plt.xlabel("Actual Quality Values")
plt.ylabel("Predicted Quality Values")





Out[278]:

Text(0, 0.5, 'Predicted Quality Values')




Regression Tree¶




Regression tree models are machine learning algorithms similar to decision trees that are used for regression problems. Regression trees are used to forecast a continuous numeric value (a real number) as the objective variable, as opposed to classification trees, which are used to classify data into discrete classifications.
The first step in using the regression tree model is to create it and fit it into a dataset.
Create a model for a regression tree with max_depth=3.



In [279]:



model3 = DecisionTreeRegressor(random_state=0, max_depth=3)
model3.fit(predictors_train, target_train)





Out[279]:



DecisionTreeRegressor(max_depth=3, random_state=0)
In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.

On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.


DecisionTreeRegressor

DecisionTreeRegressor(max_depth=3, random_state=0)



In [280]:



from matplotlib import pyplot as plt
from sklearn import tree
fig = plt.figure(figsize=(30,20))
tree.plot_tree(model3,
               feature_names=list(predictors_train.columns),
               filled=True)





Out[280]:

[Text(0.5, 0.875, 'alcohol <= 10.525\nsquared_error = 0.677\nsamples = 1119\nvalue = 5.651'),
 Text(0.25, 0.625, 'sulphates <= 0.555\nsquared_error = 0.434\nsamples = 690\nvalue = 5.384'),
 Text(0.125, 0.375, 'chlorides <= 0.169\nsquared_error = 0.281\nsamples = 230\nvalue = 5.122'),
 Text(0.0625, 0.125, 'squared_error = 0.258\nsamples = 228\nvalue = 5.136'),
 Text(0.1875, 0.125, 'squared_error = 0.25\nsamples = 2\nvalue = 3.5'),
 Text(0.375, 0.375, 'total sulfur dioxide <= 46.5\nsquared_error = 0.458\nsamples = 460\nvalue = 5.515'),
 Text(0.3125, 0.125, 'squared_error = 0.466\nsamples = 246\nvalue = 5.691'),
 Text(0.4375, 0.125, 'squared_error = 0.374\nsamples = 214\nvalue = 5.313'),
 Text(0.75, 0.625, 'sulphates <= 0.615\nsquared_error = 0.77\nsamples = 429\nvalue = 6.082'),
 Text(0.625, 0.375, 'volatile acidity <= 1.0\nsquared_error = 0.747\nsamples = 160\nvalue = 5.625'),
 Text(0.5625, 0.125, 'squared_error = 0.569\nsamples = 151\nvalue = 5.728'),
 Text(0.6875, 0.125, 'squared_error = 0.543\nsamples = 9\nvalue = 3.889'),
 Text(0.875, 0.375, 'volatile acidity <= 0.425\nsquared_error = 0.585\nsamples = 269\nvalue = 6.353'),
 Text(0.8125, 0.125, 'squared_error = 0.494\nsamples = 143\nvalue = 6.587'),
 Text(0.9375, 0.125, 'squared_error = 0.556\nsamples = 126\nvalue = 6.087')]



In [281]:



prediction_on_test = model3.predict(predictors_test)






Examine the evaluation results on testing data: MAE and RMSE



In [282]:



MAE = mean_absolute_error(target_test, prediction_on_test)
RMSE = mean_squared_error(target_test, prediction_on_test, squared=False)
print("MAE:", MAE)
print("RMSE:", RMSE)






MAE: 0.5453637284748408
RMSE: 0.6980934560458724





In [283]:



plt.figure(figsize=(8, 6))
sns.scatterplot(x=target_test, y=prediction_on_test)
plt.plot([min(target_test), max(target_test)], [min(target_test), max(target_test)], linestyle='--', color='green')
plt.title("Actual vs. Predicted(Regression Tree)")
plt.xlabel("Actual Quality Values")
plt.ylabel("Predicted Quality Values")





Out[283]:

Text(0, 0.5, 'Predicted Quality Values')



In [284]:



model4 = DecisionTreeRegressor(random_state=0, max_depth=2)
model4.fit(predictors_train, target_train)





Out[284]:



DecisionTreeRegressor(max_depth=2, random_state=0)
In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.

On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.


DecisionTreeRegressor

DecisionTreeRegressor(max_depth=2, random_state=0)



In [285]:



from matplotlib import pyplot as plt
from sklearn import tree
fig = plt.figure(figsize=(30,20))
tree.plot_tree(model4,
               feature_names=list(predictors_train.columns),
               filled=True)





Out[285]:

[Text(0.5, 0.8333333333333334, 'alcohol <= 10.525\nsquared_error = 0.677\nsamples = 1119\nvalue = 5.651'),
 Text(0.25, 0.5, 'sulphates <= 0.555\nsquared_error = 0.434\nsamples = 690\nvalue = 5.384'),
 Text(0.125, 0.16666666666666666, 'squared_error = 0.281\nsamples = 230\nvalue = 5.122'),
 Text(0.375, 0.16666666666666666, 'squared_error = 0.458\nsamples = 460\nvalue = 5.515'),
 Text(0.75, 0.5, 'sulphates <= 0.615\nsquared_error = 0.77\nsamples = 429\nvalue = 6.082'),
 Text(0.625, 0.16666666666666666, 'squared_error = 0.747\nsamples = 160\nvalue = 5.625'),
 Text(0.875, 0.16666666666666666, 'squared_error = 0.585\nsamples = 269\nvalue = 6.353')]



In [286]:



prediction_on_test = model4.predict(predictors_test)





In [287]:



MAE = mean_absolute_error(target_test, prediction_on_test)
RMSE = mean_squared_error(target_test, prediction_on_test, squared=False)
print("MAE:", MAE)
print("RMSE:", RMSE)






MAE: 0.5611052408275417
RMSE: 0.6833192648202452





In [288]:



plt.figure(figsize=(8, 6))
sns.scatterplot(x=target_test, y=prediction_on_test)
plt.plot([min(target_test), max(target_test)], [min(target_test), max(target_test)], linestyle='--', color='red')
plt.title("Actual vs. Predicted(SVR)")
plt.xlabel("Actual Quality Values")
plt.ylabel("Predicted Quality Values")





Out[288]:

Text(0, 0.5, 'Predicted Quality Values')




I constructed a regression tree model with max_depth=4 and assessed the outcomes to see how varying max-depth affected the tree's output.



In [289]:



model5 = DecisionTreeRegressor(random_state=0, max_depth=4)
model5.fit(predictors_train, target_train)





Out[289]:



DecisionTreeRegressor(max_depth=4, random_state=0)
In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.

On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.


DecisionTreeRegressor

DecisionTreeRegressor(max_depth=4, random_state=0)



In [290]:



from matplotlib import pyplot as plt
from sklearn import tree
fig = plt.figure(figsize=(30,20))
tree.plot_tree(model5,
               feature_names=list(predictors_train.columns),
               filled=True)





Out[290]:

[Text(0.5, 0.9, 'alcohol <= 10.525\nsquared_error = 0.677\nsamples = 1119\nvalue = 5.651'),
 Text(0.25, 0.7, 'sulphates <= 0.555\nsquared_error = 0.434\nsamples = 690\nvalue = 5.384'),
 Text(0.125, 0.5, 'chlorides <= 0.169\nsquared_error = 0.281\nsamples = 230\nvalue = 5.122'),
 Text(0.0625, 0.3, 'residual sugar <= 1.25\nsquared_error = 0.258\nsamples = 228\nvalue = 5.136'),
 Text(0.03125, 0.1, 'squared_error = 0.0\nsamples = 1\nvalue = 7.0'),
 Text(0.09375, 0.1, 'squared_error = 0.244\nsamples = 227\nvalue = 5.128'),
 Text(0.1875, 0.3, 'chlorides <= 0.219\nsquared_error = 0.25\nsamples = 2\nvalue = 3.5'),
 Text(0.15625, 0.1, 'squared_error = 0.0\nsamples = 1\nvalue = 4.0'),
 Text(0.21875, 0.1, 'squared_error = 0.0\nsamples = 1\nvalue = 3.0'),
 Text(0.375, 0.5, 'total sulfur dioxide <= 46.5\nsquared_error = 0.458\nsamples = 460\nvalue = 5.515'),
 Text(0.3125, 0.3, 'pH <= 3.535\nsquared_error = 0.466\nsamples = 246\nvalue = 5.691'),
 Text(0.28125, 0.1, 'squared_error = 0.413\nsamples = 227\nvalue = 5.758'),
 Text(0.34375, 0.1, 'squared_error = 0.41\nsamples = 19\nvalue = 4.895'),
 Text(0.4375, 0.3, 'alcohol <= 9.95\nsquared_error = 0.374\nsamples = 214\nvalue = 5.313'),
 Text(0.40625, 0.1, 'squared_error = 0.288\nsamples = 151\nvalue = 5.172'),
 Text(0.46875, 0.1, 'squared_error = 0.418\nsamples = 63\nvalue = 5.651'),
 Text(0.75, 0.7, 'sulphates <= 0.615\nsquared_error = 0.77\nsamples = 429\nvalue = 6.082'),
 Text(0.625, 0.5, 'volatile acidity <= 1.0\nsquared_error = 0.747\nsamples = 160\nvalue = 5.625'),
 Text(0.5625, 0.3, 'volatile acidity <= 0.365\nsquared_error = 0.569\nsamples = 151\nvalue = 5.728'),
 Text(0.53125, 0.1, 'squared_error = 0.39\nsamples = 32\nvalue = 6.281'),
 Text(0.59375, 0.1, 'squared_error = 0.513\nsamples = 119\nvalue = 5.58'),
 Text(0.6875, 0.3, 'residual sugar <= 1.9\nsquared_error = 0.543\nsamples = 9\nvalue = 3.889'),
 Text(0.65625, 0.1, 'squared_error = 0.0\nsamples = 2\nvalue = 5.0'),
 Text(0.71875, 0.1, 'squared_error = 0.245\nsamples = 7\nvalue = 3.571'),
 Text(0.875, 0.5, 'volatile acidity <= 0.425\nsquared_error = 0.585\nsamples = 269\nvalue = 6.353'),
 Text(0.8125, 0.3, 'total sulfur dioxide <= 51.5\nsquared_error = 0.494\nsamples = 143\nvalue = 6.587'),
 Text(0.78125, 0.1, 'squared_error = 0.378\nsamples = 118\nvalue = 6.703'),
 Text(0.84375, 0.1, 'squared_error = 0.678\nsamples = 25\nvalue = 6.04'),
 Text(0.9375, 0.3, 'alcohol <= 11.45\nsquared_error = 0.556\nsamples = 126\nvalue = 6.087'),
 Text(0.90625, 0.1, 'squared_error = 0.472\nsamples = 69\nvalue = 5.812'),
 Text(0.96875, 0.1, 'squared_error = 0.454\nsamples = 57\nvalue = 6.421')]



In [291]:



prediction_on_test = model5.predict(predictors_test)





In [292]:



MAE = mean_absolute_error(target_test, prediction_on_test)
RMSE = mean_squared_error(target_test, prediction_on_test, squared=False)
print("MAE:", MAE)
print("RMSE:", RMSE)






MAE: 0.5324645271825872
RMSE: 0.694266470504068






Support Vector Regression¶




For regression problems, a machine learning technique called SVR is employed. Support Vector Machines (SVM) are extended to predict continuous numerical values. Its goal is to identify the ideal hyperplane.
I utilized several values of the cost parameter C to determine which model hyperplane was optimal. I made a prediction, set the cost parameter to 1, and looked at the outcome of the first SVR model.



In [293]:



model6 = SVR(C= 1.0)
model6.fit(predictors_train, target_train)





Out[293]:



SVR()
In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.

On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.


SVR

SVR()



In [294]:



prediction_on_test = model6.predict(predictors_test)





In [295]:



MAE = mean_absolute_error(target_test, prediction_on_test)
RMSE = mean_squared_error(target_test, prediction_on_test, squared=False)
print("MAE:", MAE)
print("RMSE:", RMSE)






MAE: 0.5372875742404191
RMSE: 0.7131247064180449





In [296]:



plt.figure(figsize=(8, 6))
sns.scatterplot(x=target_test, y=prediction_on_test)
plt.plot([min(target_test), max(target_test)], [min(target_test), max(target_test)], linestyle='--', color='black')
plt.title("Actual vs. Predicted")
plt.xlabel("Actual Quality Values")
plt.ylabel("Predicted Quality Values")





Out[296]:

Text(0, 0.5, 'Predicted Quality Values')



In [297]:



model7 = SVR(C= 5.0)
model7.fit(predictors_train, target_train)





Out[297]:



SVR(C=5.0)
In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.

On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.


SVR

SVR(C=5.0)



In [298]:



prediction_on_test = model7.predict(predictors_test)






Examine the evaluation results on testing data: MAE and RMSE



In [299]:



MAE = mean_absolute_error(target_test, prediction_on_test)
RMSE = mean_squared_error(target_test, prediction_on_test, squared=False)
print("MAE:", MAE)
print("RMSE:", RMSE)






MAE: 0.5031615342665933
RMSE: 0.6544121747336556





In [300]:



model8 = SVR(C= 10.0)
model8.fit(predictors_train, target_train)





Out[300]:



SVR(C=10.0)
In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.

On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.


SVR

SVR(C=10.0)



In [301]:



prediction_on_test = model8.predict(predictors_test)





In [302]:



MAE = mean_absolute_error(target_test, prediction_on_test)
RMSE = mean_squared_error(target_test, prediction_on_test, squared=False)
print("MAE:", MAE)
print("RMSE:", RMSE)






MAE: 0.4940382849958881
RMSE: 0.6467564770982447






Out of the three models, Model 8 (SVR with C=10) has the lowest RMSE and RAE, suggesting its superior overall performance. Its forecast mistakes are the lowest. Additionally, Model 7 (SVR with C=5) functions well; its RMSE and RAE values are somewhat higher than those of Model 8, but still superior than those of Model 6. Out of the three models, Model 6 (SVR with C=1) has the greatest RMSE and RAE, indicating that its predictions are the least reliable.




MLP Model¶




An artificial neural network type utilized in deep learning and machine learning is called a multilayer perceptron.
I selected a range of MLP model sizes to generate predictions and assess each model's performance in order to determine which MLP model will perform the best with this dataset.
There are two hidden layers in the Build MLP model: the first layer has 16 hidden nodes, while the second layer has 8 hidden nodes. Put 1 for random_state.



In [303]:



model_MLP1 = MLPRegressor(hidden_layer_sizes=(16,8), random_state=1)
model_MLP1.fit(predictors_train, target_train)






/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(



Out[303]:



MLPRegressor(hidden_layer_sizes=(16, 8), random_state=1)
In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.

On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.


MLPRegressor

MLPRegressor(hidden_layer_sizes=(16, 8), random_state=1)



In [304]:



prediction_on_test = model_MLP1.predict(predictors_test)





In [305]:



MAE = mean_absolute_error(target_test, prediction_on_test)
RMSE = mean_squared_error(target_test, prediction_on_test, squared=False)
print("MAE:", MAE)
print("RMSE:", RMSE)






MAE: 0.5723368999426094
RMSE: 0.7342746057910711





In [306]:



plt.figure(figsize=(8, 6))
sns.scatterplot(x=target_test, y=prediction_on_test)
plt.plot([min(target_test), max(target_test)], [min(target_test), max(target_test)], linestyle='--', color='purple')
plt.title("Actual vs. Predicted")
plt.xlabel("Actual Quality Values")
plt.ylabel("Predicted Quality Values")





Out[306]:

Text(0, 0.5, 'Predicted Quality Values')




Three hidden layers make up the Build MLP model: the first layer has 16 hidden nodes, the second has 8 hidden nodes, and the third has 4 hidden nodes. Put 1 for random_state.



In [307]:



model_MLP2 = MLPRegressor(hidden_layer_sizes=(16,8,4), random_state=1)
model_MLP2.fit(predictors_train, target_train)






/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(



Out[307]:



MLPRegressor(hidden_layer_sizes=(16, 8, 4), random_state=1)
In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.

On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.


MLPRegressor

MLPRegressor(hidden_layer_sizes=(16, 8, 4), random_state=1)



In [308]:



prediction_on_test = model_MLP2.predict(predictors_test)





In [309]:



MAE = mean_absolute_error(target_test, prediction_on_test)
RMSE = mean_squared_error(target_test, prediction_on_test, squared=False)
print("MAE:", MAE)
print("RMSE:", RMSE)






MAE: 0.6642705192318871
RMSE: 0.8654635348835658






Three hidden layers make up the Build MLP model: the first layer has 16 hidden nodes, the second has 8 hidden nodes, and the third has 2 hidden nodes. Put 1 for random_state.



In [310]:



model_MLP3 = MLPRegressor(hidden_layer_sizes=(8,4,2), random_state=1)
model_MLP3.fit(predictors_train, target_train)






/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(



Out[310]:



MLPRegressor(hidden_layer_sizes=(8, 4, 2), random_state=1)
In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.

On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.


MLPRegressor

MLPRegressor(hidden_layer_sizes=(8, 4, 2), random_state=1)



In [311]:



prediction_on_test = model_MLP3.predict(predictors_test)





In [312]:



MAE = mean_absolute_error(target_test, prediction_on_test)
RMSE = mean_squared_error(target_test, prediction_on_test, squared=False)
print("MAE:", MAE)
print("RMSE:", RMSE)






MAE: 5.772477935712811
RMSE: 5.823368837600991






Out of the three models, Model MLP1 has the lowest RMSE and RAE, suggesting its superior overall performance. It offers the most precise forecasts.
In comparison to model MLP1, model MLP2 exhibits greater RMSE and RAE values, indicating somewhat less accurate predictions.
When compared to the other two models, model MLP3's RMSE and RAE values are noticeably greater, suggesting that it performs worse and makes fewer accurate predictions.




Result Comparison and Evaluation¶



In [313]:



result = {
    "Model": ["model1", "model2", "model3", "model4", "model5", "model6", "model7", "model8", "model_MLP1", "model_MLP2", "model_MLP3"],
    "MAE": [0.5231, 0.4871, 0.5454, 0.5611, 0.5325, 0.5373, 0.5032, 0.4940, 0.5723, 0.6643, 5.7725],
    "RMSE": [0.6623, 0.6331, 0.6981, 0.6833, 0.6943, 0.7131, 0.6544, 0.6468, 0.7343, 0.8655, 5.8234],
    "Type": ["Simple Linear Regression", "Multiple Linear Regression", "Regression Tree(3)", "Regression Tree(2)", "Regression Tree(4)",
             "SVR(1)", "SVR(5)", "SVR(10)", "MLP(16,8)", "MLP(16,8,4)", "MLP(8,4,2)"]
}
df = pd.DataFrame(result)
print(df)






         Model     MAE    RMSE                        Type
0       model1  0.5231  0.6623    Simple Linear Regression
1       model2  0.4871  0.6331  Multiple Linear Regression
2       model3  0.5454  0.6981          Regression Tree(3)
3       model4  0.5611  0.6833          Regression Tree(2)
4       model5  0.5325  0.6943          Regression Tree(4)
5       model6  0.5373  0.7131                      SVR(1)
6       model7  0.5032  0.6544                      SVR(5)
7       model8  0.4940  0.6468                     SVR(10)
8   model_MLP1  0.5723  0.7343                   MLP(16,8)
9   model_MLP2  0.6643  0.8655                 MLP(16,8,4)
10  model_MLP3  5.7725  5.8234                  MLP(8,4,2)






Because the multiple linear regression has a lower MAE and RMSE (0.4871 and 0.6331) than the linear regression model, it performs better. Regression tree models with max_depth = 2 perform better when compared to those with varying max_depths, as seen by their respective MAE and RMSE values of 0.4871 and 0.6331. The model 8(c=10) performs the best for support vector regression (MAE: 0.4940, RMSE: 0.6468).The optimal MLP model has two hidden layers: the first layer has 16 hidden nodes and the second layer has 8 hidden nodes (MAE: 0.5723, RMSE: 0.7343).
The regression tree model with max_depth = 2 is the most optimal model for the wine_quality dataset, according to the MAE and RMSE from the above table. It is possible to understand both linear and multiple linear regression by utilizing various techniques and contrasting the final results. They might not be able to depict intricate relationships, though. Regression tree models are interpretable as well, yet depending on the max_depth, they may also have an overfitting problem. Higher values of C result in reduced MAE and RMSE when examining the various cost parameters of the support vector regression model; conversely, excessively high values of C may lead to overfitting. The number of hidden layers and hidden nodes in the MLP model is a significant determinant of accuracy. Non-linear relationships may be handled by both the MLP model and support vector regression; overfitting can be prevented, though, by carefully selecting the hyperparameter.



In [314]:



!jupyter nbconvert --to html "/content/drive/MyDrive/Colab Notebooks/IS470_Assignment3.ipynb"






[NbConvertApp] Converting notebook /content/drive/MyDrive/Colab Notebooks/IS470_Assignment3.ipynb to html
[NbConvertApp] Writing 2257773 bytes to /content/drive/MyDrive/Colab Notebooks/IS470_Assignment3.html


